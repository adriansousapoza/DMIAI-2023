{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "if colab == True:\n",
    "    !pip install nnunetv2\n",
    "    !pip install torchio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import torchio as tio\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import numpy as np\n",
    "import nnunetv2\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.flush_and_unmount()\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    base_dir = '/content/drive/My Drive/Colab Notebooks/tumor-segmentation'\n",
    "    os.chdir(base_dir)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    !git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
    "    !git clone https://github.com/NVIDIA/apex\n",
    "\n",
    "    training_size = 400\n",
    "\n",
    "\n",
    "else:\n",
    "    base_dir = '/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation'\n",
    "    training_size = 200\n",
    "\n",
    "from utils import validate_segmentation, plot_prediction, dice_score\n",
    "import torchio_utils\n",
    "importlib.reload(torchio_utils)\n",
    "from torchio_utils import torchio_compose_train, plot_example\n",
    "\n",
    "path_to_mask = 'data/patients/labels/'\n",
    "path_to_imgs = 'data/patients/imgs/'\n",
    "path_to_controls = 'data/controls/imgs/' #healthy individuals (no tumors)\n",
    "dataset_path = 'data.zip'\n",
    "dataset_dir_name = 'data'\n",
    "dataset_dir = Path(dataset_dir_name)\n",
    "\n",
    "if not dataset_dir.is_dir():\n",
    "    !curl --silent --output {dataset_path} --location {dataset_url}\n",
    "    !unzip -qq {dataset_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_if_dont_exist(folder_path,overwrite=False):\n",
    "    \"\"\"\n",
    "    creates a folder if it does not exists\n",
    "    input: \n",
    "    folder_path : relative path of the folder which needs to be created\n",
    "    over_write :(default: False) if True overwrite the existing folder \n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        \n",
    "        if not overwrite:\n",
    "            print(f'{folder_path} exists.')\n",
    "        else:\n",
    "            print(f\"{folder_path} overwritten\")\n",
    "            shutil.rmtree(folder_path)\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    else:\n",
    "      os.makedirs(folder_path)\n",
    "      print(f\"{folder_path} created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/MIPPET exists.\n",
      "nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/MIPPET/imagesTr exists.\n",
      "nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/MIPPET/labelsTr exists.\n",
      "nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data/MIPPET/imagesTs exists.\n",
      "/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation/nnUNet/nnunet/nnunet_trained_models exists.\n"
     ]
    }
   ],
   "source": [
    "task_name = 'MIPPET'\n",
    "nnunet_dir = 'nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data'\n",
    "task_folder_name = os.path.join(nnunet_dir,task_name)\n",
    "train_image_dir = os.path.join(task_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(task_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(task_folder_name,'imagesTs')\n",
    "main_dir = os.path.join(base_dir,'nnUNet/nnunet')\n",
    "\n",
    "\n",
    "make_if_dont_exist(task_folder_name,overwrite = False)\n",
    "make_if_dont_exist(train_image_dir)\n",
    "make_if_dont_exist(train_label_dir)\n",
    "make_if_dont_exist(test_dir,overwrite= False)\n",
    "make_if_dont_exist(os.path.join(main_dir,'nnunet_trained_models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182 subjects\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c6f3b31754423b9bf670e935a6705b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks: [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.33322500e-02 6.22397969e-01 9.23236779e+00\n",
      " 1.72545437e+01 2.07381415e+01 2.53002322e+01 4.03121636e+01\n",
      " 1.00000000e+02]\n",
      "Augmenting 18 subjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4/18 [00:01<00:06,  2.21it/s]/home/asp/anaconda3/lib/python3.11/site-packages/torchio/transforms/transform.py:163: RuntimeWarning: Input image is 2D, but \"2\" is in axes: (0, 1, 2)\n",
      "  transformed = self.apply_transform(subject)\n",
      " 89%|████████▉ | 16/18 [00:08<00:01,  1.62it/s]"
     ]
    }
   ],
   "source": [
    "images_dir = dataset_dir / 'patients/imgs'\n",
    "labels_dir = dataset_dir / 'patients/labels'\n",
    "controls_dir = dataset_dir / 'controls/imgs'\n",
    "image_paths = sorted(images_dir.glob('*.png'))\n",
    "label_paths = sorted(labels_dir.glob('*.png'))\n",
    "control_paths = sorted(controls_dir.glob('*.png'))\n",
    "\n",
    "dataset_ID = 1\n",
    "\n",
    "dataset = torchio_compose_train(image_paths, label_paths, control_paths, \n",
    "                                cropsize=(400,991), train_size = training_size,\n",
    "                                dataset_ID=dataset_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path for your nnUNet directories\n",
    "base_path = '/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation'\n",
    "\n",
    "# Set the environment variables\n",
    "os.environ['nnUNet_raw'] = os.path.join(base_path, 'nnUNet_raw')\n",
    "os.environ['nnUNet_preprocessed'] = os.path.join(base_path, 'nnUNet_preprocessed')\n",
    "os.environ['nnUNet_results'] = os.path.join(base_path, 'nnUNet_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_plan_and_preprocess [-h] [-d D [D ...]] [-fpe FPE]\n",
      "                                    [-npfp NPFP] [--verify_dataset_integrity]\n",
      "                                    [--no_pp] [--clean] [-pl PL]\n",
      "                                    [-gpu_memory_target GPU_MEMORY_TARGET]\n",
      "                                    [-preprocessor_name PREPROCESSOR_NAME]\n",
      "                                    [-overwrite_target_spacing OVERWRITE_TARGET_SPACING [OVERWRITE_TARGET_SPACING ...]]\n",
      "                                    [-overwrite_plans_name OVERWRITE_PLANS_NAME]\n",
      "                                    [-c C [C ...]] [-np NP [NP ...]]\n",
      "                                    [--verbose]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -d D [D ...]          [REQUIRED] List of dataset IDs. Example: 2 4 5. This\n",
      "                        will run fingerprint extraction, experiment planning\n",
      "                        and preprocessing for these datasets. Can of course\n",
      "                        also be just one dataset\n",
      "  -fpe FPE              [OPTIONAL] Name of the Dataset Fingerprint Extractor\n",
      "                        class that should be used. Default is\n",
      "                        'DatasetFingerprintExtractor'.\n",
      "  -npfp NPFP            [OPTIONAL] Number of processes used for fingerprint\n",
      "                        extraction. Default: 8\n",
      "  --verify_dataset_integrity\n",
      "                        [RECOMMENDED] set this flag to check the dataset\n",
      "                        integrity. This is useful and should be done once for\n",
      "                        each dataset!\n",
      "  --no_pp               [OPTIONAL] Set this to only run fingerprint extraction\n",
      "                        and experiment planning (no preprocesing). Useful for\n",
      "                        debugging.\n",
      "  --clean               [OPTIONAL] Set this flag to overwrite existing\n",
      "                        fingerprints. If this flag is not set and a\n",
      "                        fingerprint already exists, the fingerprint extractor\n",
      "                        will not run. REQUIRED IF YOU CHANGE THE DATASET\n",
      "                        FINGERPRINT EXTRACTOR OR MAKE CHANGES TO THE DATASET!\n",
      "  -pl PL                [OPTIONAL] Name of the Experiment Planner class that\n",
      "                        should be used. Default is 'ExperimentPlanner'. Note:\n",
      "                        There is no longer a distinction between 2d and 3d\n",
      "                        planner. It's an all in one solution now. Wuch. Such\n",
      "                        amazing.\n",
      "  -gpu_memory_target GPU_MEMORY_TARGET\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom GPU memory\n",
      "                        target. Default: 8 [GB]. Changing this will affect\n",
      "                        patch and batch size and will definitely affect your\n",
      "                        models performance! Only use this if you really know\n",
      "                        what you are doing and NEVER use this without running\n",
      "                        the default nnU-Net first (as a baseline).\n",
      "  -preprocessor_name PREPROCESSOR_NAME\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom preprocessor\n",
      "                        class. This class must be located in\n",
      "                        nnunetv2.preprocessing. Default:\n",
      "                        'DefaultPreprocessor'. Changing this may affect your\n",
      "                        models performance! Only use this if you really know\n",
      "                        what you are doing and NEVER use this without running\n",
      "                        the default nnU-Net first (as a baseline).\n",
      "  -overwrite_target_spacing OVERWRITE_TARGET_SPACING [OVERWRITE_TARGET_SPACING ...]\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom target spacing\n",
      "                        for the 3d_fullres and 3d_cascade_fullres\n",
      "                        configurations. Default: None [no changes]. Changing\n",
      "                        this will affect image size and potentially patch and\n",
      "                        batch size. This will definitely affect your models\n",
      "                        performance! Only use this if you really know what you\n",
      "                        are doing and NEVER use this without running the\n",
      "                        default nnU-Net first (as a baseline). Changing the\n",
      "                        target spacing for the other configurations is\n",
      "                        currently not implemented. New target spacing must be\n",
      "                        a list of three numbers!\n",
      "  -overwrite_plans_name OVERWRITE_PLANS_NAME\n",
      "                        [OPTIONAL] uSE A CUSTOM PLANS IDENTIFIER. If you used\n",
      "                        -gpu_memory_target, -preprocessor_name or\n",
      "                        -overwrite_target_spacing it is best practice to use\n",
      "                        -overwrite_plans_name to generate a differently named\n",
      "                        plans file such that the nnunet default plans are not\n",
      "                        overwritten. You will then need to specify your custom\n",
      "                        plans file with -p whenever running other nnunet\n",
      "                        commands (training, inference etc)\n",
      "  -c C [C ...]          [OPTIONAL] Configurations for which the preprocessing\n",
      "                        should be run. Default: 2d 3d_fullres 3d_lowres.\n",
      "                        3d_cascade_fullres does not need to be specified\n",
      "                        because it uses the data from 3d_fullres.\n",
      "                        Configurations that do not exist for some dataset will\n",
      "                        be skipped.\n",
      "  -np NP [NP ...]       [OPTIONAL] Use this to define how many processes are\n",
      "                        to be used. If this is just one number then this\n",
      "                        number of processes is used for all configurations\n",
      "                        specified with -c. If it's a list of numbers this list\n",
      "                        must have as many elements as there are\n",
      "                        configurations. We then iterate over zip(configs,\n",
      "                        num_processes) to determine then umber of processes\n",
      "                        used for each configuration. More processes is always\n",
      "                        faster (up to the number of threads your PC can\n",
      "                        support, so 8 for a 4 core CPU with hyperthreading. If\n",
      "                        you don't know what that is then dont touch it, or at\n",
      "                        least don't increase it!). DANGER: More often than not\n",
      "                        the number of processes that can be used is limited by\n",
      "                        the amount of RAM available. Image resampling takes up\n",
      "                        a lot of RAM. MONITOR RAM USAGE AND DECREASE -np IF\n",
      "                        YOUR RAM FILLS UP TOO MUCH!. Default: 8 processes for\n",
      "                        2d, 4 for 3d_fullres, 8 for 3d_lowres and 4 for\n",
      "                        everything else\n",
      "  --verbose             Set this to print a lot of stuff. Useful for\n",
      "                        debugging. Will disable progress bar! Recommended for\n",
      "                        cluster environments\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset001_MyDataset\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asp/anaconda3/bin/nnUNetv2_plan_and_preprocess\", line 8, in <module>\n",
      "    sys.exit(plan_and_preprocess_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_entrypoints.py\", line 182, in plan_and_preprocess_entry\n",
      "    extract_fingerprints(args.d, args.fpe, args.npfp, args.verify_dataset_integrity, args.clean, args.verbose)\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 47, in extract_fingerprints\n",
      "    extract_fingerprint_dataset(d, fingerprint_extractor_class, num_processes, check_dataset_integrity, clean,\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 30, in extract_fingerprint_dataset\n",
      "    verify_dataset_integrity(join(nnUNet_raw, dataset_name), num_processes)\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/experiment_planning/verify_dataset_integrity.py\", line 184, in verify_dataset_integrity\n",
      "    assert all(labels_present), f'not all training cases have a label file in labelsTr. Fix that. Missing: {missing}'\n",
      "AssertionError: not all training cases have a label file in labelsTr. Fix that. Missing: ['patient_0000_', 'patient_0001_', 'patient_0002_', 'patient_0003_', 'patient_0004_', 'patient_0005_', 'patient_0006_', 'patient_0007_', 'patient_0008_', 'patient_0009_', 'patient_0010_', 'patient_0011_', 'patient_0012_', 'patient_0013_', 'patient_0014_', 'patient_0015_', 'patient_0016_', 'patient_0017_', 'patient_0018_', 'patient_0019_', 'patient_0020_', 'patient_0021_', 'patient_0022_', 'patient_0023_', 'patient_0024_', 'patient_0025_', 'patient_0026_', 'patient_0027_', 'patient_0028_', 'patient_0029_', 'patient_0030_', 'patient_0031_', 'patient_0032_', 'patient_0033_', 'patient_0034_', 'patient_0035_', 'patient_0036_', 'patient_0037_', 'patient_0038_', 'patient_0039_', 'patient_0040_', 'patient_0041_', 'patient_0042_', 'patient_0043_', 'patient_0044_', 'patient_0045_', 'patient_0046_', 'patient_0047_', 'patient_0048_', 'patient_0049_', 'patient_0050_', 'patient_0051_', 'patient_0052_', 'patient_0053_', 'patient_0054_', 'patient_0055_', 'patient_0056_', 'patient_0057_', 'patient_0058_', 'patient_0059_', 'patient_0060_', 'patient_0061_', 'patient_0062_', 'patient_0063_', 'patient_0064_', 'patient_0065_', 'patient_0066_', 'patient_0067_', 'patient_0068_', 'patient_0069_', 'patient_0070_', 'patient_0071_', 'patient_0072_', 'patient_0073_', 'patient_0074_', 'patient_0075_', 'patient_0076_', 'patient_0077_', 'patient_0078_', 'patient_0079_', 'patient_0080_', 'patient_0081_', 'patient_0082_', 'patient_0083_', 'patient_0084_', 'patient_0085_', 'patient_0086_', 'patient_0087_', 'patient_0088_', 'patient_0089_', 'patient_0090_', 'patient_0091_', 'patient_0092_', 'patient_0093_', 'patient_0094_', 'patient_0095_', 'patient_0096_', 'patient_0097_', 'patient_0098_', 'patient_0099_', 'patient_0100_', 'patient_0101_', 'patient_0102_', 'patient_0103_', 'patient_0104_', 'patient_0105_', 'patient_0106_', 'patient_0107_', 'patient_0108_', 'patient_0109_', 'patient_0110_', 'patient_0111_', 'patient_0112_', 'patient_0113_', 'patient_0114_', 'patient_0115_', 'patient_0116_', 'patient_0117_', 'patient_0118_', 'patient_0119_', 'patient_0120_', 'patient_0121_', 'patient_0122_', 'patient_0123_', 'patient_0124_', 'patient_0125_', 'patient_0126_', 'patient_0127_', 'patient_0128_', 'patient_0129_', 'patient_0130_', 'patient_0131_', 'patient_0132_', 'patient_0133_', 'patient_0134_', 'patient_0135_', 'patient_0136_', 'patient_0137_', 'patient_0138_', 'patient_0139_', 'patient_0140_', 'patient_0141_', 'patient_0142_', 'patient_0143_', 'patient_0144_', 'patient_0145_', 'patient_0146_', 'patient_0147_', 'patient_0148_', 'patient_0149_', 'patient_0150_', 'patient_0151_', 'patient_0152_', 'patient_0153_', 'patient_0154_', 'patient_0155_', 'patient_0156_', 'patient_0157_', 'patient_0158_', 'patient_0159_', 'patient_0160_', 'patient_0161_', 'patient_0162_', 'patient_0163_', 'patient_0164_', 'patient_0165_', 'patient_0166_', 'patient_0167_', 'patient_0168_', 'patient_0169_', 'patient_0170_', 'patient_0171_', 'patient_0172_', 'patient_0173_', 'patient_0174_', 'patient_0175_', 'patient_0176_', 'patient_0177_', 'patient_0178_', 'patient_0179_', 'patient_0180_', 'patient_0181_', 'patient_0182_', 'patient_0183_', 'patient_0184_', 'patient_0185_', 'patient_0186_', 'patient_0187_', 'patient_0188_', 'patient_0189_', 'patient_0190_', 'patient_0191_', 'patient_0192_', 'patient_0193_', 'patient_0194_', 'patient_0195_', 'patient_0196_', 'patient_0197_', 'patient_0198_', 'patient_0199_']\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
