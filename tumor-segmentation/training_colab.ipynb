{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nnunetv2 in /home/asp/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (2.0.1)\n",
      "Requirement already satisfied: acvl-utils>=0.2 in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (0.2)\n",
      "Requirement already satisfied: dynamic-network-architectures>=0.2 in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (0.2)\n",
      "Requirement already satisfied: tqdm in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (4.65.0)\n",
      "Requirement already satisfied: dicom2nifti in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (2.4.9)\n",
      "Requirement already satisfied: scipy in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (1.11.1)\n",
      "Requirement already satisfied: batchgenerators>=0.25 in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (0.25)\n",
      "Requirement already satisfied: numpy in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (1.2.2)\n",
      "Requirement already satisfied: scikit-image>=0.19.3 in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (0.20.0)\n",
      "Requirement already satisfied: SimpleITK>=2.2.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (2.3.1)\n",
      "Requirement already satisfied: pandas in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (2.1.3)\n",
      "Requirement already satisfied: graphviz in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (0.20.1)\n",
      "Requirement already satisfied: tifffile in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (2023.4.12)\n",
      "Requirement already satisfied: requests in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (2.31.0)\n",
      "Requirement already satisfied: nibabel in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (5.1.0)\n",
      "Requirement already satisfied: matplotlib in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (3.8.0)\n",
      "Requirement already satisfied: seaborn in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (0.12.2)\n",
      "Requirement already satisfied: imagecodecs in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (2023.1.23)\n",
      "Requirement already satisfied: yacs in /home/asp/anaconda3/lib/python3.11/site-packages (from nnunetv2) (0.1.8)\n",
      "Requirement already satisfied: connected-components-3d in /home/asp/anaconda3/lib/python3.11/site-packages (from acvl-utils>=0.2->nnunetv2) (3.12.3)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/asp/anaconda3/lib/python3.11/site-packages (from batchgenerators>=0.25->nnunetv2) (10.0.0)\n",
      "Requirement already satisfied: future in /home/asp/anaconda3/lib/python3.11/site-packages (from batchgenerators>=0.25->nnunetv2) (0.18.3)\n",
      "Requirement already satisfied: unittest2 in /home/asp/anaconda3/lib/python3.11/site-packages (from batchgenerators>=0.25->nnunetv2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl in /home/asp/anaconda3/lib/python3.11/site-packages (from batchgenerators>=0.25->nnunetv2) (3.2.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/asp/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.19.3->nnunetv2) (3.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.19.3->nnunetv2) (2.31.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.19.3->nnunetv2) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.19.3->nnunetv2) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from scikit-image>=0.19.3->nnunetv2) (0.3)\n",
      "Requirement already satisfied: filelock in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->nnunetv2) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->nnunetv2) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->nnunetv2) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->nnunetv2) (3.1.2)\n",
      "Requirement already satisfied: pydicom>=2.2.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from dicom2nifti->nnunetv2) (2.4.3)\n",
      "Requirement already satisfied: python-gdcm in /home/asp/anaconda3/lib/python3.11/site-packages (from dicom2nifti->nnunetv2) (3.0.22)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from matplotlib->nnunetv2) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/asp/anaconda3/lib/python3.11/site-packages (from matplotlib->nnunetv2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from matplotlib->nnunetv2) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from matplotlib->nnunetv2) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from matplotlib->nnunetv2) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/asp/anaconda3/lib/python3.11/site-packages (from matplotlib->nnunetv2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from pandas->nnunetv2) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from pandas->nnunetv2) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/asp/anaconda3/lib/python3.11/site-packages (from requests->nnunetv2) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/asp/anaconda3/lib/python3.11/site-packages (from requests->nnunetv2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from requests->nnunetv2) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/asp/anaconda3/lib/python3.11/site-packages (from requests->nnunetv2) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from scikit-learn->nnunetv2) (1.3.1)\n",
      "Requirement already satisfied: PyYAML in /home/asp/anaconda3/lib/python3.11/site-packages (from yacs->nnunetv2) (6.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/asp/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->nnunetv2) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/asp/anaconda3/lib/python3.11/site-packages (from sympy->torch>=2.0.0->nnunetv2) (1.3.0)\n",
      "Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2)\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: traceback2 in /home/asp/anaconda3/lib/python3.11/site-packages (from unittest2->batchgenerators>=0.25->nnunetv2) (1.4.0)\n",
      "Requirement already satisfied: linecache2 in /home/asp/anaconda3/lib/python3.11/site-packages (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2) (1.0.0)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Requirement already satisfied: torchio in /home/asp/anaconda3/lib/python3.11/site-packages (0.19.2)\n",
      "Requirement already satisfied: Deprecated in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (1.2.14)\n",
      "Requirement already satisfied: SimpleITK!=2.0.*,!=2.1.1.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (2.3.1)\n",
      "Requirement already satisfied: humanize in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (4.8.0)\n",
      "Requirement already satisfied: nibabel in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (1.26.0)\n",
      "Requirement already satisfied: scipy in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (4.65.0)\n",
      "Requirement already satisfied: typer[all] in /home/asp/anaconda3/lib/python3.11/site-packages (from torchio) (0.9.0)\n",
      "Requirement already satisfied: filelock in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=1.1->torchio) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=1.1->torchio) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=1.1->torchio) (1.12)\n",
      "Requirement already satisfied: networkx in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=1.1->torchio) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/asp/anaconda3/lib/python3.11/site-packages (from torch>=1.1->torchio) (3.1.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/asp/anaconda3/lib/python3.11/site-packages (from Deprecated->torchio) (1.14.1)\n",
      "Requirement already satisfied: packaging>=17 in /home/asp/anaconda3/lib/python3.11/site-packages (from nibabel->torchio) (23.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from typer[all]->torchio) (8.1.6)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /home/asp/anaconda3/lib/python3.11/site-packages (from typer[all]->torchio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from typer[all]->torchio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from typer[all]->torchio) (13.6.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/asp/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.1->torchio) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/asp/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/asp/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]->torchio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "colab = False\n",
    "\n",
    "if colab == True:\n",
    "    !pip install nnunetv2\n",
    "    !pip install torchio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation/training_colab.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation/training_colab.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnnunetv2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation/training_colab.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m colab:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation/training_colab.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation/training_colab.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     drive\u001b[39m.\u001b[39mflush_and_unmount()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation/training_colab.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m, force_remount\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import torchio as tio\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import numpy as np\n",
    "import nnunetv2\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.flush_and_unmount()\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    base_dir = '/content/drive/My Drive/Colab Notebooks/tumor-segmentation'\n",
    "    os.chdir(base_dir)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    !git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
    "    !git clone https://github.com/NVIDIA/apex\n",
    "\n",
    "    training_size = 400\n",
    "\n",
    "\n",
    "else:\n",
    "    base_dir = '/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation'\n",
    "    training_size = 200\n",
    "\n",
    "from utils import validate_segmentation, plot_prediction, dice_score\n",
    "import torchio_utils\n",
    "importlib.reload(torchio_utils)\n",
    "from torchio_utils import torchio_compose_train, plot_example\n",
    "\n",
    "path_to_mask = 'data/patients/labels/'\n",
    "path_to_imgs = 'data/patients/imgs/'\n",
    "path_to_controls = 'data/controls/imgs/' #healthy individuals (no tumors)\n",
    "dataset_path = 'data.zip'\n",
    "dataset_dir_name = 'data'\n",
    "dataset_dir = Path(dataset_dir_name)\n",
    "\n",
    "if not dataset_dir.is_dir():\n",
    "    !curl --silent --output {dataset_path} --location {dataset_url}\n",
    "    !unzip -qq {dataset_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182 subjects\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd48345669fb4cc0bd2cb7c6668ae587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks: [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.33322500e-02 6.22397969e-01 9.23236779e+00\n",
      " 1.72545437e+01 2.07381415e+01 2.53002322e+01 4.03121636e+01\n",
      " 1.00000000e+02]\n",
      "Augmenting 18 subjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3/18 [00:01<00:08,  1.78it/s]/home/asp/anaconda3/lib/python3.11/site-packages/torchio/transforms/transform.py:163: RuntimeWarning: Input image is 2D, but \"2\" is in axes: (0, 1, 2)\n",
      "  transformed = self.apply_transform(subject)\n",
      "100%|██████████| 18/18 [00:09<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 200 subjects to nnUNet_raw/Dataset001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 85.11it/s]\n"
     ]
    }
   ],
   "source": [
    "images_dir = dataset_dir / 'patients/imgs'\n",
    "labels_dir = dataset_dir / 'patients/labels'\n",
    "controls_dir = dataset_dir / 'controls/imgs'\n",
    "image_paths = sorted(images_dir.glob('*.png'))\n",
    "label_paths = sorted(labels_dir.glob('*.png'))\n",
    "control_paths = sorted(controls_dir.glob('*.png'))\n",
    "\n",
    "dataset_ID = 1\n",
    "\n",
    "dataset = torchio_compose_train(image_paths, label_paths, control_paths, \n",
    "                                cropsize=(400,991), train_size = training_size,\n",
    "                                dataset_ID=dataset_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path for your nnUNet directories\n",
    "base_path = '/home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation'\n",
    "\n",
    "# Set the environment variables\n",
    "os.environ['nnUNet_raw'] = os.path.join(base_path, 'nnUNet_raw')\n",
    "os.environ['nnUNet_preprocessed'] = os.path.join(base_path, 'nnUNet_preprocessed')\n",
    "os.environ['nnUNet_results'] = os.path.join(base_path, 'nnUNet_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_plan_and_preprocess [-h] [-d D [D ...]] [-fpe FPE]\n",
      "                                    [-npfp NPFP] [--verify_dataset_integrity]\n",
      "                                    [--no_pp] [--clean] [-pl PL]\n",
      "                                    [-gpu_memory_target GPU_MEMORY_TARGET]\n",
      "                                    [-preprocessor_name PREPROCESSOR_NAME]\n",
      "                                    [-overwrite_target_spacing OVERWRITE_TARGET_SPACING [OVERWRITE_TARGET_SPACING ...]]\n",
      "                                    [-overwrite_plans_name OVERWRITE_PLANS_NAME]\n",
      "                                    [-c C [C ...]] [-np NP [NP ...]]\n",
      "                                    [--verbose]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -d D [D ...]          [REQUIRED] List of dataset IDs. Example: 2 4 5. This\n",
      "                        will run fingerprint extraction, experiment planning\n",
      "                        and preprocessing for these datasets. Can of course\n",
      "                        also be just one dataset\n",
      "  -fpe FPE              [OPTIONAL] Name of the Dataset Fingerprint Extractor\n",
      "                        class that should be used. Default is\n",
      "                        'DatasetFingerprintExtractor'.\n",
      "  -npfp NPFP            [OPTIONAL] Number of processes used for fingerprint\n",
      "                        extraction. Default: 8\n",
      "  --verify_dataset_integrity\n",
      "                        [RECOMMENDED] set this flag to check the dataset\n",
      "                        integrity. This is useful and should be done once for\n",
      "                        each dataset!\n",
      "  --no_pp               [OPTIONAL] Set this to only run fingerprint extraction\n",
      "                        and experiment planning (no preprocesing). Useful for\n",
      "                        debugging.\n",
      "  --clean               [OPTIONAL] Set this flag to overwrite existing\n",
      "                        fingerprints. If this flag is not set and a\n",
      "                        fingerprint already exists, the fingerprint extractor\n",
      "                        will not run. REQUIRED IF YOU CHANGE THE DATASET\n",
      "                        FINGERPRINT EXTRACTOR OR MAKE CHANGES TO THE DATASET!\n",
      "  -pl PL                [OPTIONAL] Name of the Experiment Planner class that\n",
      "                        should be used. Default is 'ExperimentPlanner'. Note:\n",
      "                        There is no longer a distinction between 2d and 3d\n",
      "                        planner. It's an all in one solution now. Wuch. Such\n",
      "                        amazing.\n",
      "  -gpu_memory_target GPU_MEMORY_TARGET\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom GPU memory\n",
      "                        target. Default: 8 [GB]. Changing this will affect\n",
      "                        patch and batch size and will definitely affect your\n",
      "                        models performance! Only use this if you really know\n",
      "                        what you are doing and NEVER use this without running\n",
      "                        the default nnU-Net first (as a baseline).\n",
      "  -preprocessor_name PREPROCESSOR_NAME\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom preprocessor\n",
      "                        class. This class must be located in\n",
      "                        nnunetv2.preprocessing. Default:\n",
      "                        'DefaultPreprocessor'. Changing this may affect your\n",
      "                        models performance! Only use this if you really know\n",
      "                        what you are doing and NEVER use this without running\n",
      "                        the default nnU-Net first (as a baseline).\n",
      "  -overwrite_target_spacing OVERWRITE_TARGET_SPACING [OVERWRITE_TARGET_SPACING ...]\n",
      "                        [OPTIONAL] DANGER ZONE! Sets a custom target spacing\n",
      "                        for the 3d_fullres and 3d_cascade_fullres\n",
      "                        configurations. Default: None [no changes]. Changing\n",
      "                        this will affect image size and potentially patch and\n",
      "                        batch size. This will definitely affect your models\n",
      "                        performance! Only use this if you really know what you\n",
      "                        are doing and NEVER use this without running the\n",
      "                        default nnU-Net first (as a baseline). Changing the\n",
      "                        target spacing for the other configurations is\n",
      "                        currently not implemented. New target spacing must be\n",
      "                        a list of three numbers!\n",
      "  -overwrite_plans_name OVERWRITE_PLANS_NAME\n",
      "                        [OPTIONAL] uSE A CUSTOM PLANS IDENTIFIER. If you used\n",
      "                        -gpu_memory_target, -preprocessor_name or\n",
      "                        -overwrite_target_spacing it is best practice to use\n",
      "                        -overwrite_plans_name to generate a differently named\n",
      "                        plans file such that the nnunet default plans are not\n",
      "                        overwritten. You will then need to specify your custom\n",
      "                        plans file with -p whenever running other nnunet\n",
      "                        commands (training, inference etc)\n",
      "  -c C [C ...]          [OPTIONAL] Configurations for which the preprocessing\n",
      "                        should be run. Default: 2d 3d_fullres 3d_lowres.\n",
      "                        3d_cascade_fullres does not need to be specified\n",
      "                        because it uses the data from 3d_fullres.\n",
      "                        Configurations that do not exist for some dataset will\n",
      "                        be skipped.\n",
      "  -np NP [NP ...]       [OPTIONAL] Use this to define how many processes are\n",
      "                        to be used. If this is just one number then this\n",
      "                        number of processes is used for all configurations\n",
      "                        specified with -c. If it's a list of numbers this list\n",
      "                        must have as many elements as there are\n",
      "                        configurations. We then iterate over zip(configs,\n",
      "                        num_processes) to determine then umber of processes\n",
      "                        used for each configuration. More processes is always\n",
      "                        faster (up to the number of threads your PC can\n",
      "                        support, so 8 for a 4 core CPU with hyperthreading. If\n",
      "                        you don't know what that is then dont touch it, or at\n",
      "                        least don't increase it!). DANGER: More often than not\n",
      "                        the number of processes that can be used is limited by\n",
      "                        the amount of RAM available. Image resampling takes up\n",
      "                        a lot of RAM. MONITOR RAM USAGE AND DECREASE -np IF\n",
      "                        YOUR RAM FILLS UP TOO MUCH!. Default: 8 processes for\n",
      "                        2d, 4 for 3d_fullres, 8 for 3d_lowres and 4 for\n",
      "                        everything else\n",
      "  --verbose             Set this to print a lot of stuff. Useful for\n",
      "                        debugging. Will disable progress bar! Recommended for\n",
      "                        cluster environments\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset001\n",
      "Using <class 'nnunetv2.imageio.natural_image_reager_writer.NaturalImage2DIO'> as reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.natural_image_reager_writer.NaturalImage2DIO'> as reader/writer\n",
      "100%|█████████████████████████████████████████| 200/200 [00:05<00:00, 34.90it/s]\n",
      "Experiment planning...\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 8, 'patch_size': array([384, 512]), 'median_image_size_in_voxels': array([333., 488.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.natural_image_reager_writer.NaturalImage2DIO'> as reader/writer\n",
      "Plans were saved to /home/asp/Downloads/DMIAI/DMIAI_2023/tumor-segmentation/nnUNet_preprocessed/Dataset001/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset001\n",
      "Configuration: 2d...\n",
      "100%|█████████████████████████████████████████| 200/200 [00:06<00:00, 32.65it/s]\n",
      "Configuration: 3d_fullres...\n",
      "INFO: Configuration 3d_fullres not found in plans file nnUNetPlans.json of dataset Dataset001. Skipping.\n",
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset001. Skipping.\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_train [-h] [-tr TR] [-p P]\n",
      "                      [-pretrained_weights PRETRAINED_WEIGHTS]\n",
      "                      [-num_gpus NUM_GPUS] [--use_compressed] [--npz] [--c]\n",
      "                      [--val] [--val_best] [--disable_checkpointing]\n",
      "                      [-device DEVICE]\n",
      "                      dataset_name_or_id configuration fold\n",
      "\n",
      "positional arguments:\n",
      "  dataset_name_or_id    Dataset name or ID to train with\n",
      "  configuration         Configuration that should be trained\n",
      "  fold                  Fold of the 5-fold cross-validation. Should be an int\n",
      "                        between 0 and 4.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -tr TR                [OPTIONAL] Use this flag to specify a custom trainer.\n",
      "                        Default: nnUNetTrainer\n",
      "  -p P                  [OPTIONAL] Use this flag to specify a custom plans\n",
      "                        identifier. Default: nnUNetPlans\n",
      "  -pretrained_weights PRETRAINED_WEIGHTS\n",
      "                        [OPTIONAL] path to nnU-Net checkpoint file to be used\n",
      "                        as pretrained model. Will only be used when actually\n",
      "                        training. Beta. Use with caution.\n",
      "  -num_gpus NUM_GPUS    Specify the number of GPUs to use for training\n",
      "  --use_compressed      [OPTIONAL] If you set this flag the training cases\n",
      "                        will not be decompressed. Reading compressed data is\n",
      "                        much more CPU and (potentially) RAM intensive and\n",
      "                        should only be used if you know what you are doing\n",
      "  --npz                 [OPTIONAL] Save softmax predictions from final\n",
      "                        validation as npz files (in addition to predicted\n",
      "                        segmentations). Needed for finding the best ensemble.\n",
      "  --c                   [OPTIONAL] Continue training from latest checkpoint\n",
      "  --val                 [OPTIONAL] Set this flag to only run the validation.\n",
      "                        Requires training to have finished.\n",
      "  --val_best            [OPTIONAL] If set, the validation will be performed\n",
      "                        with the checkpoint_best instead of checkpoint_final.\n",
      "                        NOT COMPATIBLE with --disable_checkpointing! WARNING:\n",
      "                        This will use the same 'validation' folder as the\n",
      "                        regular validation with no way of distinguishing the\n",
      "                        two!\n",
      "  --disable_checkpointing\n",
      "                        [OPTIONAL] Set this flag to disable checkpointing.\n",
      "                        Ideal for testing things out and you dont want to\n",
      "                        flood your hard drive with checkpoints.\n",
      "  -device DEVICE        Use this to set the device the training should run\n",
      "                        with. Available options are 'cuda' (GPU), 'cpu' (CPU)\n",
      "                        and 'mps' (Apple M1/M2). Do NOT use this to set which\n",
      "                        GPU ID! Use CUDA_VISIBLE_DEVICES=X nnUNetv2_train\n",
      "                        [...] instead!\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following only works with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "/home/asp/anaconda3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asp/anaconda3/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/run/run_training.py\", line 268, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/run/run_training.py\", line 204, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1234, in run_training\n",
      "    self.on_train_start()\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 793, in on_train_start\n",
      "    self.initialize()\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 207, in initialize\n",
      "    enable_deep_supervision=True).to(self.device)\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1145, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 4 more times]\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1143, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/asp/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py\", line 239, in _lazy_init\n",
      "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
      "AssertionError: Torch not compiled with CUDA enabled\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train Dataset001 2d 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
