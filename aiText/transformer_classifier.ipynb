{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to build an AI text detector, that can detect if a text is written by an AI or a human\n",
    "\n",
    "# 0. load packages\n",
    "# 1. get the data\n",
    "# 2. preprocess the data (embeddings)\n",
    "# 3. build the model\n",
    "# 4. train the model\n",
    "# 5. evaluate the model\n",
    "# 6. save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Det gør firmaerne, der står bag AI'en - eksemp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tror det bliver for kedeligt, hvis vi bare læs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Godt spørgsmål! Det er nemlig meget, meget svæ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ja, det er begyndt at ske. Det er dog ikke så ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Det vil jeg tro - uden at vide det helt præcis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Selvom det er svært at forudsige, hvornår AI v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Det afhænger nok meget af, hvor fremme i skoen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>En tech-korrespondent er en journalist, der dæ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ChatGPT er en generativ AI-model, der lærer at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hej, den har læst en masse tekst og så regner ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_generated\n",
       "0  Det gør firmaerne, der står bag AI'en - eksemp...             0\n",
       "1  Tror det bliver for kedeligt, hvis vi bare læs...             0\n",
       "2  Godt spørgsmål! Det er nemlig meget, meget svæ...             0\n",
       "3  Ja, det er begyndt at ske. Det er dog ikke så ...             1\n",
       "4  Det vil jeg tro - uden at vide det helt præcis...             0\n",
       "5  Selvom det er svært at forudsige, hvornår AI v...             1\n",
       "6  Det afhænger nok meget af, hvor fremme i skoen...             0\n",
       "7  En tech-korrespondent er en journalist, der dæ...             1\n",
       "8  ChatGPT er en generativ AI-model, der lærer at...             1\n",
       "9  Hej, den har læst en masse tekst og så regner ...             0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. get the data\n",
    "filename = 'data.csv'\n",
    "df = pd.read_csv(filename, header=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. preprocess the data (embeddings)\n",
    "def get_embeddings(df):\n",
    "        \n",
    "    # build a vocabulary\n",
    "    vocab = {}\n",
    "    rvocab = {}\n",
    "    c = 0\n",
    "    for text in df['text']:\n",
    "        for word in text.split():\n",
    "            if word not in vocab:\n",
    "                vocab[word] = c\n",
    "                rvocab[c] = word\n",
    "                c += 1\n",
    "\n",
    "    # build the embeddings\n",
    "    embeddings = np.random.rand(len(vocab), 10)\n",
    "\n",
    "\n",
    "    # build the training data\n",
    "    X = []\n",
    "\n",
    "    for text in df['text']:\n",
    "        x = []\n",
    "        for word in text.split():\n",
    "            x.append(embeddings[vocab[word]])\n",
    "        X.append(np.array(x))\n",
    "\n",
    "    # add padding\n",
    "    maxlen = max([len(x) for x in X])\n",
    "    for i in range(len(X)):\n",
    "        X[i] = np.concatenate([X[i], np.zeros((maxlen - len(X[i]), 10))])\n",
    "\n",
    "    X = np.array(X)\n",
    "\n",
    "    y = df['is_generated'].values\n",
    "    return X, y, vocab, rvocab, embeddings\n",
    "X, y, vocab, rvocab, embeddings = get_embeddings(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.7021608889102936\n",
      "Epoch 10 loss: 0.6992170155048371\n",
      "Epoch 20 loss: 0.6904897034168244\n",
      "Epoch 30 loss: 0.6713377237319946\n",
      "Epoch 40 loss: 0.6405147790908814\n",
      "Epoch 50 loss: 0.5772414594888687\n",
      "Epoch 60 loss: 0.5189620643854141\n",
      "Epoch 70 loss: 0.45294628739356996\n",
      "Epoch 80 loss: 0.3704911023378372\n",
      "Epoch 90 loss: 0.3028962671756744\n"
     ]
    }
   ],
   "source": [
    "# 3. build the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        X, y, vocab, rvocab, embeddings = get_embeddings(df)\n",
    "        self.X = X\n",
    "        self.y = torch.Tensor(y)\n",
    "        self.len = len(y)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "# model should be transformer based\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextModel, self).__init__()\n",
    "\n",
    "        # embedding\n",
    "        # self.embedding = nn.Embedding(10000, 10)\n",
    "        \n",
    "        \n",
    "        # transformer encoder\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=10, nhead=2, dim_feedforward=1048, dropout=0.1, activation='relu'\n",
    "            ),\n",
    "            num_layers=6\n",
    "        )\n",
    "\n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(163, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 1), # should maybe be 2\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 3. train the model\n",
    "model = TextModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "dataset = TextDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss_accum = 0\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X = X.squeeze(0)\n",
    "        # convert to float 32\n",
    "        X = X.float()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_accum += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss_accum/len(dataloader)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fucking'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/tonton/Documents/DMIAI23/aiText/playground.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tonton/Documents/DMIAI23/aiText/playground.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m x \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tonton/Documents/DMIAI23/aiText/playground.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m text\u001b[39m.\u001b[39msplit():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tonton/Documents/DMIAI23/aiText/playground.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     x\u001b[39m.\u001b[39mappend(embeddings[vocab[word]])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tonton/Documents/DMIAI23/aiText/playground.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tonton/Documents/DMIAI23/aiText/playground.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# add padding\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fucking'"
     ]
    }
   ],
   "source": [
    "# 5. evaluate the model\n",
    "\n",
    "text = 'Jeg er fucking ikke en AI'\n",
    "\n",
    "# convert text to embedding\n",
    "x = []\n",
    "for word in text.split():\n",
    "    x.append(embeddings[vocab[word]])\n",
    "x = np.array(x)\n",
    "\n",
    "# add padding\n",
    "maxlen = 163\n",
    "x = np.concatenate([x, np.zeros((maxlen - len(x), 10))])\n",
    "x = np.array([x])\n",
    "\n",
    "# convert to float 32\n",
    "x = torch.Tensor(x).float()\n",
    "# predict\n",
    "y_pred = model(x.squeeze(0))\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
